AI-Generated Voice Detection (Multi-Language)

DhvaniSense is an API-based system that detects whether a given voice sample is AI-generated or Human, across multiple languages, using audio signal processing and a lightweight machine learning model enhanced with a custom Micro-Prosody Entropy Score (MPES).


ğŸ“˜ README.md â€” DhvaniSense
AI-Generated Voice Detection API

(End-to-End Setup â†’ Final URL Generation)

This project provides a REST API that detects whether a given voice sample is AI-generated or Human.
Follow the steps below exactly in order to run the project and generate the final API URL.

âœ… Step 0 â€” Prerequisites

Ensure the following are installed on your system:

1ï¸âƒ£ Python

Version 3.9 or above

Verify:

python --version

2ï¸âƒ£ FFmpeg (Required for MP3 decoding)

Download from: https://www.gyan.dev/ffmpeg/builds/

Extract and add the bin/ folder to system PATH

Verify:

ffmpeg -version

ğŸ“¦ Step 1 â€” Install Python Dependencies

Open the project folder in VS Code and open a terminal.

From the project root:

pip install -r requirements.txt


This installs:

FastAPI

Uvicorn

PyTorch

Librosa

NumPy

SciPy

Pydub

ğŸ§ Step 2 â€” Prepare the Training Dataset

Ensure training audio is placed as follows:

training/dataset/
â”œâ”€â”€ human/
â”‚   â”œâ”€â”€ human1.mp3
â”‚   â”œâ”€â”€ human2.mp3
â”‚   â””â”€â”€ ...
â””â”€â”€ ai/
    â”œâ”€â”€ ai1.mp3
    â”œâ”€â”€ ai2.mp3
    â””â”€â”€ ...


Rules:

MP3 format only

One speaker per file

Avoid empty or noisy audio

ğŸ§  Step 3 â€” Train the Model

From the project root:

cd training
python train.py
cd ..


What this does:

Loads training audio

Extracts MFCC features

Trains a neural network

Saves trained weights to:

api/model_weights.pth


âš ï¸ This step is required only once, unless you add more data or modify training logic.

ğŸš€ Step 4 â€” Start the API Server

From the project root:

cd api
uvicorn app:app


If successful, you will see:

Uvicorn running on http://127.0.0.1:8000

ğŸŒ Step 5 â€” Final Generated URLs

Once the server is running, the following URLs are available:

ğŸ”¹ Base API URL
http://127.0.0.1:8000

ğŸ”¹ API Endpoint URL (for requests)
http://127.0.0.1:8000/api/voice-detection

ğŸ”¹ Interactive API Documentation (Swagger UI)
http://127.0.0.1:8000/docs


ğŸ‘‰ This /docs URL is the final URL used for testing and validation.

ğŸ” Step 6 â€” API Authentication

All requests must include the following header:

x-api-key: sk_dhvanisense_2026


Requests without this key will be rejected.

ğŸ“¡ Step 7 â€” Test the API (Example)
Request Body
{
  "language": "English",
  "audioFormat": "mp3",
  "audioBase64": "<BASE64_ENCODED_MP3>"
}

Response Example
{
  "status": "success",
  "language": "English",
  "classification": "AI_GENERATED",
  "confidenceScore": 0.63,
  "explanation": "Unnatural pitch consistency and robotic speech patterns detected"
}

ğŸ” Restarting After Shutdown

If the laptop is restarted:

cd api
uvicorn app:app


No retraining is required if model_weights.pth exists.

ğŸ§  Summary (One-Line)

After training the model and starting the FastAPI server, the final usable URL is
http://127.0.0.1:8000/docs
